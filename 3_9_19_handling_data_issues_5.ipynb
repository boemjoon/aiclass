{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boemjoon/aiclass/blob/main/3_9_19_handling_data_issues_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhmH5Q7uuJKi"
      },
      "source": [
        "# Handling duplicate, missing, or invalid data\n",
        "\n",
        "## About the data\n",
        "In this notebook, we will using daily weather data that was taken from the [National Centers for Environmental Information (NCEI) API](https://www.ncdc.noaa.gov/cdo-web/webservices/v2) and altered to introduce many common problems faced when working with data.\n",
        "\n",
        "*Note: The NCEI is part of the National Oceanic and Atmospheric Administration (NOAA) and, as you can see from the URL for the API, this resource was created when the NCEI was called the NCDC. Should the URL for this resource change in the future, you can search for \"NCEI weather API\" to find the updated one.*\n",
        "\n",
        "## Background on the data\n",
        "\n",
        "Data meanings:\n",
        "- `PRCP`: precipitation in millimeters\n",
        "- `SNOW`: snowfall in millimeters\n",
        "- `SNWD`: snow depth in millimeters\n",
        "- `TMAX`: maximum daily temperature in Celsius\n",
        "- `TMIN`: minimum daily temperature in Celsius\n",
        "- `TOBS`: temperature at time of observation in Celsius\n",
        "- `WESF`: water equivalent of snow in millimeters\n",
        "\n",
        "Some important facts to get our bearings:\n",
        "- According to the National Weather Service, the coldest temperature ever recorded in Central Park was -15°F (-26.1°C) on February 9, 1934: [source](https://www.weather.gov/media/okx/Climate/CentralPark/extremes.pdf)\n",
        "- The temperature of the Sun's photosphere is approximately 5,505°C: [source](https://en.wikipedia.org/wiki/Sun)\n",
        "\n",
        "## Setup\n",
        "We need to import `pandas` and read in the dirty data to get started:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_03/data/bitcoin.csv\n",
        "\n",
        "!wget https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_03/data/dirty_data.csv\n",
        "\n",
        "!wget https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_03/data/long_data.csv\n",
        "\n",
        "!wget https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_03/data/nyc_temperatures.csv\n",
        "\n",
        "!wget https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_03/data/sp500.csv\n",
        "\n",
        "!wget https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_03/data/wide_data.csv\n",
        "\n",
        "!mkdir data\n",
        "\n",
        "!mv *.csv data"
      ],
      "metadata": {
        "id": "qGuN2CVuzG7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUOozdqZuJKk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data/dirty_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOX789mluJKk"
      },
      "source": [
        "## Finding problematic data\n",
        "A good first step is to look at some rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nJANfYiuJKl",
        "outputId": "680af901-37fc-4584-8ad4-cbc73fc6ff46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>station</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>TOBS</th>\n",
              "      <th>WESF</th>\n",
              "      <th>inclement_weather</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-01T00:00:00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-inf</td>\n",
              "      <td>5505.0</td>\n",
              "      <td>-40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-01T00:00:00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-inf</td>\n",
              "      <td>5505.0</td>\n",
              "      <td>-40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-01T00:00:00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-inf</td>\n",
              "      <td>5505.0</td>\n",
              "      <td>-40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-02T00:00:00</td>\n",
              "      <td>GHCND:USC00280907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-inf</td>\n",
              "      <td>-8.3</td>\n",
              "      <td>-16.1</td>\n",
              "      <td>-12.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-03T00:00:00</td>\n",
              "      <td>GHCND:USC00280907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-inf</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-13.9</td>\n",
              "      <td>-13.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  date            station  PRCP  SNOW  SNWD    TMAX  TMIN  \\\n",
              "0  2018-01-01T00:00:00                  ?   0.0   0.0  -inf  5505.0 -40.0   \n",
              "1  2018-01-01T00:00:00                  ?   0.0   0.0  -inf  5505.0 -40.0   \n",
              "2  2018-01-01T00:00:00                  ?   0.0   0.0  -inf  5505.0 -40.0   \n",
              "3  2018-01-02T00:00:00  GHCND:USC00280907   0.0   0.0  -inf    -8.3 -16.1   \n",
              "4  2018-01-03T00:00:00  GHCND:USC00280907   0.0   0.0  -inf    -4.4 -13.9   \n",
              "\n",
              "   TOBS  WESF inclement_weather  \n",
              "0   NaN   NaN               NaN  \n",
              "1   NaN   NaN               NaN  \n",
              "2   NaN   NaN               NaN  \n",
              "3 -12.2   NaN             False  \n",
              "4 -13.3   NaN             False  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur1_drOMuJKl"
      },
      "source": [
        "Looking at summary statistics can reveal strange or missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQ3em21EuJKl",
        "outputId": "1b965470-6048-4404-b40b-dcd4186bd883"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/stefaniemolin/book_env/lib/python3.7/site-packages/numpy/lib/function_base.py:3968: RuntimeWarning: invalid value encountered in multiply\n",
            "  x2 = take(ap, indices_above, axis=axis) * weights_above\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>TOBS</th>\n",
              "      <th>WESF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>765.000000</td>\n",
              "      <td>577.000000</td>\n",
              "      <td>577.0</td>\n",
              "      <td>765.000000</td>\n",
              "      <td>765.000000</td>\n",
              "      <td>398.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.360392</td>\n",
              "      <td>4.202773</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2649.175294</td>\n",
              "      <td>-15.914379</td>\n",
              "      <td>8.632161</td>\n",
              "      <td>16.290909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10.002138</td>\n",
              "      <td>25.086077</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2744.156281</td>\n",
              "      <td>24.242849</td>\n",
              "      <td>9.815054</td>\n",
              "      <td>9.489832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-inf</td>\n",
              "      <td>-11.700000</td>\n",
              "      <td>-40.000000</td>\n",
              "      <td>-16.100000</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.300000</td>\n",
              "      <td>-40.000000</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>8.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.800000</td>\n",
              "      <td>-11.100000</td>\n",
              "      <td>8.300000</td>\n",
              "      <td>19.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5505.000000</td>\n",
              "      <td>6.700000</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>24.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>61.700000</td>\n",
              "      <td>229.000000</td>\n",
              "      <td>inf</td>\n",
              "      <td>5505.000000</td>\n",
              "      <td>23.900000</td>\n",
              "      <td>26.100000</td>\n",
              "      <td>28.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             PRCP        SNOW   SNWD         TMAX        TMIN        TOBS  \\\n",
              "count  765.000000  577.000000  577.0   765.000000  765.000000  398.000000   \n",
              "mean     5.360392    4.202773    NaN  2649.175294  -15.914379    8.632161   \n",
              "std     10.002138   25.086077    NaN  2744.156281   24.242849    9.815054   \n",
              "min      0.000000    0.000000   -inf   -11.700000  -40.000000  -16.100000   \n",
              "25%      0.000000    0.000000    NaN    13.300000  -40.000000    0.150000   \n",
              "50%      0.000000    0.000000    NaN    32.800000  -11.100000    8.300000   \n",
              "75%      5.800000    0.000000    NaN  5505.000000    6.700000   18.300000   \n",
              "max     61.700000  229.000000    inf  5505.000000   23.900000   26.100000   \n",
              "\n",
              "            WESF  \n",
              "count  11.000000  \n",
              "mean   16.290909  \n",
              "std     9.489832  \n",
              "min     1.800000  \n",
              "25%     8.600000  \n",
              "50%    19.300000  \n",
              "75%    24.900000  \n",
              "max    28.700000  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcAJZtMsuJKm"
      },
      "source": [
        "The `info()` method can pinpoint missing values and wrong data types:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxKGBueWuJKm",
        "outputId": "89d48c04-a774-457f-addd-957644815bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 765 entries, 0 to 764\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   date               765 non-null    object \n",
            " 1   station            765 non-null    object \n",
            " 2   PRCP               765 non-null    float64\n",
            " 3   SNOW               577 non-null    float64\n",
            " 4   SNWD               577 non-null    float64\n",
            " 5   TMAX               765 non-null    float64\n",
            " 6   TMIN               765 non-null    float64\n",
            " 7   TOBS               398 non-null    float64\n",
            " 8   WESF               11 non-null     float64\n",
            " 9   inclement_weather  408 non-null    object \n",
            "dtypes: float64(7), object(3)\n",
            "memory usage: 59.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJC52MFVuJKm"
      },
      "source": [
        "We can use the `isna()`/`isnull()` method of the series to find nulls:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AKqK04TuJKm",
        "outputId": "a2e2af87-3ab0-4430-adeb-41e013c85efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cf0341f4b62a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m contain_nulls = df[\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSNOW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSNWD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTOBS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m|\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWESF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclement_weather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      5\u001b[0m \u001b[0mcontain_nulls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "contain_nulls = df[\n",
        "    df.SNOW.isna() | df.SNWD.isna() | df.TOBS.isna()\n",
        "    | df.WESF.isna() | df.inclement_weather.isna()\n",
        "]\n",
        "contain_nulls.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKauTXaZuJKn",
        "outputId": "f40ee170-bd0e-4185-da7c-5bf08a2f3852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'contain_nulls' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a0c9ce3aeaab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontain_nulls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'contain_nulls' is not defined"
          ]
        }
      ],
      "source": [
        "contain_nulls.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m49JrclGuJKn"
      },
      "source": [
        "Note that we can't check if we have `NaN` like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC4BqgQHuJKo"
      },
      "outputs": [],
      "source": [
        "df[df.inclement_weather == 'NaN'].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9hlduWZuJKo"
      },
      "source": [
        "This is because it is actually `np.nan`. However, notice this also doesn't work:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbWLeZYZuJKo",
        "outputId": "3a730e44-bc63-4234-c303-1ab992d91dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-91cafe5d28c5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclement_weather\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "df[df.inclement_weather == np.nan].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN30t2bIuJKo"
      },
      "source": [
        "We have to use one of the methods discussed earlier for this to work:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOtgZP47uJKp"
      },
      "outputs": [],
      "source": [
        "df[df.inclement_weather.isna()].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oetuLLTPuJKp"
      },
      "source": [
        "We can find `-inf`/`inf` by comparing to `-np.inf`/`np.inf`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLhSEpTxuJKp",
        "outputId": "1ea2fd69-4dae-4c4f-850b-883b319c69e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-afaa74b62f77>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSNWD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df[df.SNWD.isin([-np.inf, np.inf])].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVEuW84UuJKp"
      },
      "source": [
        "Rather than do this for each column, we can write a function that will use a [dictionary comprehension](https://www.python.org/dev/peps/pep-0274/) to check all the columns for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWm98iBOuJKq"
      },
      "outputs": [],
      "source": [
        "def get_inf_count(df):\n",
        "    \"\"\"Find the number of inf/-inf values per column in the dataframe\"\"\"\n",
        "    return {\n",
        "        col: df[df[col].isin([np.inf, -np.inf])].shape[0] for col in df.columns\n",
        "    }\n",
        "\n",
        "get_inf_count(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgMU9009uJKq"
      },
      "source": [
        "Before we can decide how to handle the infinite values of snow depth, we should look at the summary statistics for snowfall, which forms a big part in determining the snow depth:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqzgnHVeuJKq"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\n",
        "    'np.inf Snow Depth': df[df.SNWD == np.inf].SNOW.describe(),\n",
        "    '-np.inf Snow Depth': df[df.SNWD == -np.inf].SNOW.describe()\n",
        "}).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsXLYa_NuJKq"
      },
      "source": [
        "Let's now look into the `date` and `station` columns. We saw the `?` for station earlier, so we know that was the other unique value. However, we see that some dates are present 8 times in the data and we only have 324 days meaning we are also missing days:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1_YdzomuJKr"
      },
      "outputs": [],
      "source": [
        "df.describe(include='object')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmk4d_S-uJKr"
      },
      "source": [
        "We can use the `duplicated()` method to find duplicate rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XIvXk8ZuJKr"
      },
      "outputs": [],
      "source": [
        "df[df.duplicated()].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMIRnJBZuJKr"
      },
      "source": [
        "The default for `keep` is `'first'` meaning it won't show the first row that the duplicated data was seen in; we can pass in `False` to see it though:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geF_zBkMuJKr"
      },
      "outputs": [],
      "source": [
        "df[df.duplicated(keep=False)].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhhQs4UcuJKs"
      },
      "source": [
        "We can also specify the columns to use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2S7GYHjuJKs"
      },
      "outputs": [],
      "source": [
        "df[df.duplicated(['date', 'station'])].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icsgrYdauJKs"
      },
      "source": [
        "Let's look at a few duplicates. Just in the few values we see here, we know that the top 4 are actually in the data 6 times because by default we aren't seeing their first occurrence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDWLZTcauJKs"
      },
      "outputs": [],
      "source": [
        "df[df.duplicated()].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sVxqL0YuJKs"
      },
      "source": [
        "## Mitigating Issues\n",
        "\n",
        "### Handling duplicated data\n",
        "Since we know we have NY weather data and noticed we only had two entries for `station`, we may decide to drop the `station` column because we are only interested in the weather data. However, when dealing with duplicate data, we need to think of the ramifications of removing it. Notice we only have data for the `WESF` column when the station is `?`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwdGJOiYuJKt"
      },
      "outputs": [],
      "source": [
        "df[df.WESF.notna()].station.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDXSsRcYuJKt"
      },
      "source": [
        "If we determine it won't impact our analysis, we can use `drop_duplicates()` to remove them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPie2MBmuJKt"
      },
      "outputs": [],
      "source": [
        "# 1. make the date a datetime\n",
        "df.date = pd.to_datetime(df.date)\n",
        "\n",
        "# 2. save this information for later\n",
        "station_qm_wesf = df[df.station == '?'].drop_duplicates('date').set_index('date').WESF\n",
        "\n",
        "# 3. sort ? to the bottom\n",
        "df.sort_values('station', ascending=False, inplace=True)\n",
        "\n",
        "# 4. drop duplicates based on the date column keeping the first occurrence\n",
        "# which will be the valid station if it has data\n",
        "df_deduped = df.drop_duplicates('date')\n",
        "\n",
        "# 5. remove the station column because we are done with it\n",
        "df_deduped = df_deduped.drop(columns='station').set_index('date').sort_index()\n",
        "\n",
        "# 6. take valid station's WESF and fall back on station ? if it is null\n",
        "df_deduped = df_deduped.assign(\n",
        "    WESF=lambda x: x.WESF.combine_first(station_qm_wesf)\n",
        ")\n",
        "\n",
        "df_deduped.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1oNkUryuJKt"
      },
      "source": [
        "Here we used the `combine_first()` method to coalesce the values to the first non-null entry; this means that if we had data from both stations, we would first take the value provided by the named station and if (and only if) that station was null would we take the value from the station named `?`. The following table contains some examples of how this would play out:\n",
        "\n",
        "| station GHCND:USC00280907 | station ? | result of `combine_first()` |\n",
        "| :---: | :---: | :---: |\n",
        "| 1 | 17 | 1 |\n",
        "| 1 | `NaN` | 1 |\n",
        "| `NaN` | 17 | 17 |\n",
        "| `NaN` | `NaN` | `NaN` |\n",
        "\n",
        "Check out the 4th row&mdash;we have `WESF` in the correct spot thanks to the index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l9I_5szuJKt"
      },
      "outputs": [],
      "source": [
        "df_deduped.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Pi64NBuJK0"
      },
      "source": [
        "### Dealing with nulls\n",
        "We could drop nulls, replace them with some arbitrary value, or impute them using the surrounding data. Each of these options may have ramifications, so we must choose wisely.\n",
        "\n",
        "We can use `dropna()` to drop rows where any column has a null value. The default options leave us hardly any data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QPZcomluJK0"
      },
      "outputs": [],
      "source": [
        "df_deduped.dropna().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIrlXuV5uJK1"
      },
      "source": [
        "If we pass `how='all'`, we can choose to only drop rows where everything is null, but this removes nothing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb3UGSdcuJK1",
        "outputId": "f0660d3b-25e4-4eb3-d98a-0d26ac7ed056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_deduped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-432e720ccedc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_deduped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_deduped' is not defined"
          ]
        }
      ],
      "source": [
        "df_deduped.dropna(how='all').shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4K0r-XKuJK1"
      },
      "source": [
        "We can use just a subset of columns to determine what to drop with the `subset` argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AocSDlkxuJK1",
        "outputId": "5c05eb7e-2000-4c7b-8f05-3afc07e09a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_deduped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a451c5d645a2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_deduped.dropna(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inclement_weather'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SNOW'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SNWD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ).shape\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_deduped' is not defined"
          ]
        }
      ],
      "source": [
        "df_deduped.dropna(\n",
        "    how='all', subset=['inclement_weather', 'SNOW', 'SNWD']\n",
        ").shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l21a_5ejuJK2"
      },
      "source": [
        "This can also be performed along columns, and we can also require a certain number of null values before we drop the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WREIEucjuJK2"
      },
      "outputs": [],
      "source": [
        "df_deduped.dropna(axis='columns', thresh=df_deduped.shape[0] * .75).columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLtghct7uJK2"
      },
      "source": [
        "We can choose to fill in the null values instead with `fillna()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ781jMXuJK2"
      },
      "outputs": [],
      "source": [
        "df_deduped.loc[:,'WESF'].fillna(0, inplace=True)\n",
        "df_deduped.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwGmtgqSuJK3"
      },
      "source": [
        "At this point we have done everything we can without distorting the data. We know that we are missing dates, but if we reindex, we don't know how to fill in the `NaN` data. With the weather data, we can't assume because it snowed one day that it will snow the next or that the temperature will be the same. For this reason, note that the next few examples are just for illustrative purposes only—just because we can do something doesn't mean we should.\n",
        "\n",
        "That being said, let's try to address some of remaining issues with the temperature data. We know that when `TMAX` is the temperature of the Sun, it must be because there was no measured value, so let's replace it with `NaN`. We will also do so for `TMIN` which currently uses -40°C for its placeholder when we know that the coldest temperature ever recorded in NYC was -15°F (-26.1°C) on February 9, 1934:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mkj18ckuJK3"
      },
      "outputs": [],
      "source": [
        "df_deduped = df_deduped.assign(\n",
        "    TMAX=lambda x: x.TMAX.replace(5505, np.nan),\n",
        "    TMIN=lambda x: x.TMIN.replace(-40, np.nan),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIEkU3kauJK3"
      },
      "source": [
        "We will also make an assumption that the temperature won't change drastically day-to-day. Note that this is actually a big assumption, but it will allow us to understand how `fillna()` works when we provide a strategy through the `method` parameter. The `fillna()` method gives us 2 options for the `method` parameter:\n",
        "- `'ffill'` to forward-fill\n",
        "- `'bfill'` to back-fill\n",
        "\n",
        "*Note that `'nearest'` is missing because we are not reindexing.*\n",
        "\n",
        "Here, we will use `'ffill'` to show how this works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMMRZfNouJK4",
        "outputId": "63c8d0e7-32af-4e17-ee2e-bdf76acfc0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_deduped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ff8cf51965ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_deduped.assign(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mTMAX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTMAX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ffill'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTMIN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTMIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ffill'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ).head()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_deduped' is not defined"
          ]
        }
      ],
      "source": [
        "df_deduped.assign(\n",
        "    TMAX=lambda x: x.TMAX.fillna(method='ffill'),\n",
        "    TMIN=lambda x: x.TMIN.fillna(method='ffill')\n",
        ").head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46p5mkctuJK4"
      },
      "source": [
        "We can use `np.nan_to_num()` to turn `np.nan` into 0 and `-np.inf`/`np.inf` into large negative or positive finite numbers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH1UC4NDuJK4",
        "outputId": "fe22b1c0-8e2c-423d-b88d-b9110c17217a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_deduped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ec7d802e025a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_deduped.assign(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mSNWD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSNWD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ).head()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_deduped' is not defined"
          ]
        }
      ],
      "source": [
        "df_deduped.assign(\n",
        "    SNWD=lambda x: np.nan_to_num(x.SNWD)\n",
        ").head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ-iPUIbuJK4"
      },
      "source": [
        "Depending on the data we are working with, we can use the `clip()` method as an alternative to `np.nan_to_num()`. The `clip()` method makes it possible to cap values at a specific minimum and/or maximum threshold. Since `SNWD` can't be negative, let's use `clip()` to enforce a lower bound of zero. To show how the upper bound works, let's use the value of `SNOW`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klym7aeduJK5",
        "outputId": "537497cf-6473-4701-f4a5-9b5970360d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_deduped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-96c27544acc4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_deduped.assign(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mSNWD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSNWD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSNOW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ).head()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_deduped' is not defined"
          ]
        }
      ],
      "source": [
        "df_deduped.assign(\n",
        "    SNWD=lambda x: x.SNWD.clip(0, x.SNOW)\n",
        ").head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo6HYp5CuJK5"
      },
      "source": [
        "We can couple `fillna()` with other types of calculations. Here we replace missing values of `TMAX` with the median of all `TMAX` values, `TMIN` with the median of all `TMIN` values, and `TOBS` to the average of the `TMAX` and `TMIN` values. Since we place `TOBS` last, we have access to the imputed values for `TMIN` and `TMAX` in the calculation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPV1eS4puJK5",
        "outputId": "009e9035-e3e8-44b3-cab5-e5a2861a908d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_deduped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8c257ae17326>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_deduped.assign(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mTMAX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTMAX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTMAX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTMIN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTMIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTMIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# average of TMAX and TMIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mTOBS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTOBS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTMAX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTMIN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_deduped' is not defined"
          ]
        }
      ],
      "source": [
        "df_deduped.assign(\n",
        "    TMAX=lambda x: x.TMAX.fillna(x.TMAX.median()),\n",
        "    TMIN=lambda x: x.TMIN.fillna(x.TMIN.median()),\n",
        "    # average of TMAX and TMIN\n",
        "    TOBS=lambda x: x.TOBS.fillna((x.TMAX + x.TMIN) / 2)\n",
        ").head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZLv3eALuJK5"
      },
      "source": [
        "We can also use `apply()` for running the same calculation across columns. For example, let's fill all missing values with their rolling 7-day median of their values, setting the number of periods required for the calculation to 0 to ensure we don't introduce more extra `NaN` values. Rolling calculations will be covered in chapter 4, so this is a preview:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AMgXyomuJK6",
        "outputId": "b18539ed-172b-4e94-8600-f48926c2cb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_deduped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-16a5af7808e7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_deduped.apply(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# rolling calculations will be covered in chapter 4, this is a rolling 7-day median\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# we set min_periods (# of periods required for calculation) to 0 so we always get a result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ).head(10)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_deduped' is not defined"
          ]
        }
      ],
      "source": [
        "df_deduped.apply(\n",
        "    # rolling calculations will be covered in chapter 4, this is a rolling 7-day median\n",
        "    # we set min_periods (# of periods required for calculation) to 0 so we always get a result\n",
        "    lambda x: x.fillna(x.rolling(7, min_periods=0).median())\n",
        ").head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZphymwuuJK6"
      },
      "source": [
        "The last strategy we could try is interpolation with the `interpolate()` method. We specify the `method` parameter with the interpolation strategy to use. There are many options, but we will stick with the default of `'linear'`, which will treat values as evenly spaced and place missing values in the middle of existing ones. We have some missing data, so we will reindex first. Look at January 9th, which we didn't have before—the values for `TMAX`, `TMIN`, and `TOBS` are the average of values the day prior (January 8th) and the day after (January 10th):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKr-TUh_uJK6",
        "outputId": "83f516d1-4d04-4c88-e5dc-a26c3fb1f491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_deduped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d70a1674e6d3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_deduped\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2018-01-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2018-12-31'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_deduped' is not defined"
          ]
        }
      ],
      "source": [
        "df_deduped\\\n",
        "    .reindex(pd.date_range('2018-01-01', '2018-12-31', freq='D'))\\\n",
        "    .apply(lambda x: x.interpolate())\\\n",
        "    .head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhX3Wl1huJK6"
      },
      "source": [
        "<hr>\n",
        "\n",
        "<div style=\"overflow: hidden; margin-bottom: 10px;\">\n",
        "    <div style=\"float: left;\">\n",
        "         <a href=\"./4-reshaping_data.ipynb\">\n",
        "            <button>&#8592; Previous Notebook</button>\n",
        "        </a>\n",
        "    </div>\n",
        "    <div style=\"float: right;\">\n",
        "        <a href=\"../../solutions/ch_03/solutions.ipynb\">\n",
        "            <button>Solutions</button>\n",
        "        </a>\n",
        "        <a href=\"../ch_04/1-querying_and_merging.ipynb\">\n",
        "            <button>Chapter 4 &#8594;</button>\n",
        "        </a>\n",
        "    </div>\n",
        "</div>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uHnrlVvSztBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}